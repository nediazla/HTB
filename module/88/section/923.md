# Mejorando continuamente el código

---

En este punto, tenemos un script de Python en funcionamiento que extraerá palabras de una página web e imprimirá las 10 principales más que se encuentran en la consola.

Supongamos que nuestro compromiso nos exigió contar palabras en dos páginas web. Luego necesitaríamos repetir grandes cantidades del código anterior para la nueva página web. Alternativamente, podríamos_Refactor_el código actual y mueva la parte de conteo de palabras a su función.

#### Extraer el código de conteo a su función

Código:pitón

```python
def count_occurrences_in(word_list):
    word_count = {}
    for word in word_list:
        if word not in word_count:
            word_count[word] = 1
        else:
            current_count = word_count.get(word)
            word_count[word] = current_count + 1
    return word_count
```

Observe cómo agregamos un parámetro de entrada y reemplazamos la lista de palabras para iterar a este nuevo`word_list`parámetro. También agregamos un`return statement`En la parte inferior para que nuestra función pueda devolver el resultado. Podemos hacer lo mismo para el código que actualmente actúa como pegamento en nuestro script:

#### Current Glue

Código:pitón

```python
html = get_html_of(PAGE_URL)
soup = BeautifulSoup(html, 'html.parser')
raw_text = soup.get_text()
all_words = re.findall(r'\w+', raw_text)
```

Simplemente reemplazando el`PAGE_URL`constante (por nombrar la convención, no es constante) con el`url`variable y devolver el resultado de la expresión regular`findall`Llame, hemos convertido el pegamento estático en código reutilizable:

#### Refactorizado a su función

Código:pitón

```python
def get_all_words_from(url):
    html = get_html_of(url)
    soup = BeautifulSoup(html, 'html.parser')
    raw_text = soup.get_text()
    return re.findall(r'\w+', raw_text)

all_words = get_all_words_from(PAGE_URL)
```

Si realizamos el mismo ejercicio para el código restante, obtenemos esto:

#### Refactorizar el código restante

Código:pitón

```python
import requests
import re
from bs4 import BeautifulSoup

PAGE_URL = 'http://target:port'

def get_html_of(url):
    resp = requests.get(url)

    if resp.status_code != 200:
        print(f'HTTP status code of {resp.status_code} returned, but 200 was expected. Exiting...')
        exit(1)

    return resp.content.decode()

def count_occurrences_in(word_list):
    word_count = {}

    for word in word_list:
        if word not in word_count:
            word_count[word] = 1
        else:
            current_count = word_count.get(word)
            word_count[word] = current_count + 1
    return word_count

def get_all_words_from(url):
    html = get_html_of(url)
    soup = BeautifulSoup(html, 'html.parser')
    raw_text = soup.get_text()
    return re.findall(r'\w+', raw_text)

def get_top_words_from(all_words):
    occurrences = count_occurrences_in(all_words)
    return sorted(occurrences.items(), key=lambda item: item[1], reverse=True)

all_words = get_all_words_from(PAGE_URL)
top_words = get_top_words_from(all_words)

for i in range(10):
    print(top_words[i][0])
```

Observe, además de lo anterior, la siguiente pieza de código reflectado.

#### Pegamento, pero más limpio

Código:pitón

```python
def get_top_words_from(url):
    all_words = get_all_words_from(url)
    occurrences = count_occurrences_in(all_words)
    return sorted(occurrences.items(), key=lambda item: item[1], reverse=True)
```

Esta función toma una URL como parámetro y luego usa inmediatamente la URL para llamar a otra función que obtiene la lista de palabras necesarias. Esta refactorización adicional hizo que el código fuera un poco más limpio y más fácil de leer`in this situation`. Si tuviéramos que rastrear diez páginas, tendríamos que reflector una vez más, no repetirnos una y otra vez. Alternativamente, podríamos cargar una lista de URL de un archivo de texto, hacer la recopilación de palabras para cada URL y agregar los datos al final. Sin embargo, en lugar de tratar de resolver un problema que no existe, sigamos adelante.